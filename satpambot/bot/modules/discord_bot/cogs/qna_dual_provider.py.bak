<<<<<<< HEAD
from __future__ import annotations

import logging
from discord.ext import commands

LOGGER = logging.getLogger(__name__)
QNA_CHANNEL_ID = 1426571542627614772

class QnaDualProvider(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        LOGGER.info("QnA ready (static id=%s)", QNA_CHANNEL_ID)

async def setup(bot: commands.Bot):
    await bot.add_cog(QnaDualProvider(bot))
=======

import os, json, asyncio, base64
from typing import Optional, List, Dict, Any

try:
    import httpx  # preferred since project already uses httpx
except Exception:  # pragma: no cover
    httpx = None

import discord
from discord.ext import commands

DEFAULT_GROQ_MODEL = os.environ.get("QNA_GROQ_MODEL") or "llama-3.1-8b-instant"
DEFAULT_GEMINI_MODEL = os.environ.get("QNA_GEMINI_MODEL") or "gemini-1.5-flash"

def _load_local_json() -> Dict[str, Any]:
    paths = ["data/local.json", "data/config/local.json", "local.json", "config/local.json"]
    for p in paths:
        if os.path.exists(p):
            try:
                with open(p, "r", encoding="utf-8") as fh:
                    return json.load(fh)
            except Exception:
                pass
    return {}

def _as_bool(v, default=False):
    if isinstance(v, bool):
        return v
    if v is None:
        return default
    s = str(v).strip().lower()
    return s in ("1","true","yes","on","y","enable","enabled")

class QnaDualProvider(commands.Cog):
    """Reply in a dedicated QnA channel using Groq with Gemini fallback.
    Requires mention unless overridden, to avoid spam.
    Supports image attachments (falls back to Gemini for vision)."""

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        cfg = _load_local_json()
        self.qna_channel_id = int(str(os.environ.get("QNA_CHANNEL_ID") or cfg.get("QNA_CHANNEL_ID", 0)) or 0)
        self.mention_required = _as_bool(os.environ.get("QNA_MENTION_REQUIRED", cfg.get("QNA_MENTION_REQUIRED", True)), True)
        self.provider_order = cfg.get("QNA_PROVIDER_ORDER") or (os.environ.get("QNA_PROVIDER_ORDER") or "groq,gemini").split(",")
        self.provider_order = [p.strip().lower() for p in self.provider_order if p.strip()]
        self.groq_key = os.environ.get("GROQ_API_KEY") or os.environ.get("GROQ_KEY")
        self.gemini_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY") or os.environ.get("GOOGLE_GENAI_KEY")
        self.timeout = float(os.environ.get("QNA_HTTP_TIMEOUT", "25"))
        self.allow_owner_bypass = _as_bool(os.environ.get("QNA_OWNER_BYPASS", cfg.get("QNA_OWNER_BYPASS", True)), True)

    # ------------ Providers ------------

    async def _ask_groq(self, prompt: str) -> Optional[str]:
        if not self.groq_key or httpx is None:
            return None
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {"Authorization": f"Bearer {self.groq_key}"}
        data = {
            "model": DEFAULT_GROQ_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "max_tokens": 1024,
        }
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                r = await client.post(url, headers=headers, json=data)
                if r.status_code != 200:
                    return None
                j = r.json()
                return j.get("choices", [{}])[0].get("message", {}).get("content")
        except Exception:
            return None

    async def _ask_gemini_text(self, prompt: str) -> Optional[str]:
        if not self.gemini_key or httpx is None:
            return None
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{DEFAULT_GEMINI_MODEL}:generateContent?key={self.gemini_key}"
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                r = await client.post(url, json=payload)
                if r.status_code != 200:
                    return None
                j = r.json()
                candidates = j.get("candidates") or []
                if not candidates:
                    return None
                parts = candidates[0].get("content", {}).get("parts") or []
                texts = [p.get("text","") for p in parts if "text" in p]
                return "\n".join([t for t in texts if t]).strip() or None
        except Exception:
            return None

    async def _ask_gemini_vision(self, prompt: str, images: List[bytes]) -> Optional[str]:
        if not self.gemini_key or httpx is None:
            return None
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{DEFAULT_GEMINI_MODEL}:generateContent?key={self.gemini_key}"
        parts = [{"text": prompt or "Analyze the image(s) and answer the user question."}]
        for data in images:
            b64 = base64.b64encode(data).decode("ascii")
            parts.append({
                "inline_data": {
                    "mime_type": "image/png",  # discord attachments are often png/jpg; server will auto-detect
                    "data": b64
                }
            })
        payload = {"contents": [{"parts": parts}]}
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                r = await client.post(url, json=payload)
                if r.status_code != 200:
                    return None
                j = r.json()
                candidates = j.get("candidates") or []
                if not candidates:
                    return None
                parts = candidates[0].get("content", {}).get("parts") or []
                texts = [p.get("text","") for p in parts if "text" in p]
                return "\n".join([t for t in texts if t]).strip() or None
        except Exception:
            return None

    async def _ask_providers(self, prompt: str, images: List[bytes]) -> Optional[str]:
        # Vision: prefer Gemini first when images exist
        order = list(self.provider_order)
        if images:
            if "gemini" in order:
                first = ["gemini"] + [p for p in order if p != "gemini"]
                order = first

        for provider in order:
            if provider == "groq" and not images:
                ans = await self._ask_groq(prompt)
                if ans:
                    return ans
            elif provider == "gemini":
                if images:
                    ans = await self._ask_gemini_vision(prompt, images)
                else:
                    ans = await self._ask_gemini_text(prompt)
                if ans:
                    return ans
        return None

    # ------------ Event ------------
    @commands.Cog.listener("on_message")
    async def on_message(self, message: discord.Message):
        if not self.qna_channel_id:
            return
        if not message or not message.channel or message.author.bot:
            return
        if getattr(message.channel, "id", None) != self.qna_channel_id:
            return

        # Enforce mention requirement unless owner/mod
        requires_mention = self.mention_required
        if requires_mention:
            is_owner = False
            try:
                is_owner = await self.bot.is_owner(message.author)
            except Exception:
                pass
            if self.allow_owner_bypass and is_owner:
                requires_mention = False
            if requires_mention and self.bot.user not in message.mentions:
                return

        # Collect text + images
        prompt = (message.content or "").strip()
        images: List[bytes] = []
        for att in message.attachments or []:
            if att.content_type and att.content_type.startswith("image/"):
                try:
                    images.append(await att.read())
                except Exception:
                    continue

        # Ask LLMs with fallback
        async with message.channel.typing():
            reply = await self._ask_providers(prompt, images)

        if not reply:
            reply = "Maaf, semua provider QnA sedang sibuk. Coba lagi sebentar ya."

        try:
            await message.reply(reply, mention_author=False)
        except Exception:
            # Best effort
            try:
                await message.channel.send(reply)
            except Exception:
                pass

async def setup(bot: commands.Bot):  # for discord.py >=2.0
    try:
        res = await bot.add_cog(QnaDualProvider(bot))
    except TypeError:
        await bot.add_cog(QnaDualProvider(bot))

def setup_legacy(bot):  # fallback for older loaders
    try:
        await bot.add_cog(QnaDualProvider(bot))
    except Exception:
        pass

def setup(bot):  # common entry for various loaders
    try:
        bot.loop.create_task(setup(bot))  # type: ignore
    except Exception:
        try:
            await bot.add_cog(QnaDualProvider(bot))
        except Exception:
            QnaDualProvider(bot)  # import side-effect for smoke

# appended by patch: make setup safe-await
import asyncio
async def setup_safe(bot):
    res = await bot.add_cog(QnADualProvider(bot))
    if asyncio.iscoroutine(res):
        await res
>>>>>>> ef940a8 (heal)
