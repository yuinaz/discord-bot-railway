
from __future__ import annotations
import os, json, time, logging, asyncio, hashlib
from pathlib import Path
from typing import Dict, List, Optional

import discord
from discord.ext import commands, tasks
try:
    from satpambot.bot.llm.groq_client import groq_chat  # prefer user's
except Exception:
    from satpambot.bot.llm._groq_client_suite import groq_chat  # fallback

try:
    from satpambot.bot.modules.discord_bot.cogs.neuro_memory_core import MemoryStore  # prefer user's
except Exception:
    from satpambot.bot.modules.discord_bot.cogs._neuro_memory_core_suite import MemoryStore  # fallback

log = logging.getLogger(__name__)

SETTINGS_PATH = os.getenv("NEURO_AUTOLEARN_SETTINGS", "data/neuro_autolearn.json")
DEFAULT_PERIOD = int(os.getenv("NEURO_AUTOLEARN_PERIOD", "420"))
BATCH_LIMIT = int(os.getenv("NEURO_AUTOLEARN_BATCH", "30"))
OWNER_USER_ID = int(os.getenv("OWNER_USER_ID", "0") or "0")
REPORT_CHANNEL_ID = int(os.getenv("NEURO_REPORT_CHANNEL_ID", "0") or "0")
XP_PER_MEMORY = int(os.getenv("NEURO_XP_PER_MEMORY", "5"))
MAX_POSTS_PER_HR = int(os.getenv("NEURO_AUTOLEARN_MAX_POSTS_PER_HR", "2"))
CHANNELS_PRESET = os.getenv("NEURO_AUTOLEARN_CHANNELS_PRESET", "").strip()

SYSTEM_PROMPT = (
  "You are a security-minded assistant that extracts LEARNINGS from Discord log messages. "
  "Return compact JSON: {\"memories\": [str], \"summary\": str, \"help_needed\": bool, \"notify\": str}. "
  "Memories are short general rules/indicators (<=140 chars each), no secrets/IDs. Indonesian output."
)

def _load_settings() -> dict:
    p = Path(SETTINGS_PATH)
    if not p.exists():
        p.parent.mkdir(parents=True, exist_ok=True)
        preset = {}
        if CHANNELS_PRESET:
            for cid in CHANNELS_PRESET.split(","):
                cid = cid.strip()
                if cid.isdigit():
                    preset[cid] = {"last_id": None}
        p.write_text(json.dumps({"channels": preset, "enabled": True}, indent=2))
    try:
        return json.loads(p.read_text())
    except Exception:
        return {"channels": {}, "enabled": True}

def _save_settings(cfg: dict):
    p = Path(SETTINGS_PATH); p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(json.dumps(cfg, indent=2))

def _truncate_chunks(msgs: List[str], max_chars: int = 8000) -> str:
    out, total = [], 0
    for m in msgs:
        m = m.strip()
        if not m: continue
        if total + len(m) + 2 > max_chars: break
        out.append(m); total += len(m) + 1
    return "\n".join(out)

def _load_quota() -> dict:
    p = Path("data/neuro_autolearn_quota.json")
    if not p.exists(): return {"posts": []}
    try: return json.loads(p.read_text())
    except Exception: return {"posts": []}

def _save_quota(d: dict):
    p = Path("data/neuro_autolearn_quota.json"); p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(json.dumps(d))

def _may_post() -> bool:
    q = _load_quota()
    now = time.time()
    q["posts"] = [t for t in q.get("posts", []) if now - t < 3600]
    if len(q["posts"]) >= MAX_POSTS_PER_HR:
        return False
    q["posts"].append(now); _save_quota(q)
    return True

class NeuroAutoLearnModeratedV2(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.db: MemoryStore = getattr(bot, "_neuro_db", None) or MemoryStore()
        setattr(bot, "_neuro_db", self.db)
        self.cfg = _load_settings()
        self._scan.start()

    def cog_unload(self):
        try: self._scan.cancel()
        except Exception: pass

    @tasks.loop(seconds=DEFAULT_PERIOD)
    async def _scan(self):
        await self.bot.wait_until_ready()
        try:
            await self._do_scan()
        except Exception:
            log.exception("autolearn scan error")

    async def _do_scan(self) -> int:
        cfg = self.cfg; chs = cfg.get("channels", {})
        added_total = 0
        for k, meta in chs.items():
            try:
                cid = int(k)
                ch = self.bot.get_channel(cid) or await self.bot.fetch_channel(cid)
            except Exception:
                log.warning("Channel %s tidak ditemukan/akses ditolak.", k)
                continue

            after_id = meta.get("last_id", None)
            after_obj = discord.Object(id=int(after_id)) if after_id else None

            msgs, last_seen = [], after_id
            try:
                async for m in ch.history(limit=BATCH_LIMIT, oldest_first=True, after=after_obj):
                    s = (m.content or "").strip()
                    if s:
                        ts = int(m.created_at.timestamp())
                        msgs.append(f"[{ts}] {s}")
                    last_seen = m.id
            except Exception:
                log.exception("Gagal membaca history %s", k)
                continue

            if not msgs:
                continue

            chunk = _truncate_chunks(msgs, max_chars=8000)
            user = ("Berikut potongan pesan log Discord (urut lama->baru). "
                    "Ekstrak 3-8 pelajaran sebagai rules/indikator singkat. "
                    "Jika ambigu/berbahaya, set help_needed true & beri notify ringkas.\n\n"
                    "[LOGS]\n" + chunk)

            try:
                txt = await groq_chat([
                    {"role":"system","content": SYSTEM_PROMPT},
                    {"role":"user","content": user},
                ], max_tokens=650, temperature=0.2)
            except Exception as e:
                log.exception("Groq gagal: %s", e)
                continue

            import re, json as _json
            mems: List[str] = []
            summary = ""; help_needed = False; notify = ""
            m = re.search(r"\{.*\}", txt, re.S)
            if m:
                try:
                    obj = _json.loads(m.group(0))
                    mems = [str(x) for x in obj.get("memories", []) if str(x).strip()][:12]
                    summary = str(obj.get("summary",""))
                    help_needed = bool(obj.get("help_needed", False))
                    notify = str(obj.get("notify",""))
                except Exception:
                    pass
            if not mems:
                mems = [s.strip("-â€¢ ").strip() for s in txt.splitlines() if s.strip()][:8]

            def norm(s: str) -> str:
                return " ".join(s.lower().split())
            hashes_path = Path("data/neuro_autolearn_hashes.json")
            known = set()
            if hashes_path.exists():
                try: known = set(json.loads(hashes_path.read_text()).get("h", []))
                except Exception: known = set()
            new_mems = []
            for s in mems:
                h = hashlib.sha256(norm(s).encode("utf-8")).hexdigest()[:16]
                if h in known: continue
                known.add(h); new_mems.append(s)
            hashes_path.parent.mkdir(parents=True, exist_ok=True)
            hashes_path.write_text(json.dumps({"h": list(known)}, indent=0))

            for s in new_mems:
                try:
                    self.db.upsert(ch.guild.id if hasattr(ch,"guild") and ch.guild else 0, ch.id, 0, s, tags="autolearn,phish_log")
                    added_total += 1
                except Exception:
                    pass
            if new_mems:
                try:
                    self.bot.dispatch("neuro_memories_added", {"channel_id": ch.id, "count": len(new_mems), "items": new_mems})
                    if XP_PER_MEMORY > 0:
                        self.bot.dispatch("neuro_xp", {"points": XP_PER_MEMORY * len(new_mems), "source": "autolearn", "channel_id": ch.id})
                except Exception:
                    pass

            if last_seen:
                cfg["channels"][k]["last_id"] = int(last_seen)
                _save_settings(cfg); self.cfg = cfg

            if not new_mems and not help_needed:
                continue
            if not _may_post():
                continue

            try:
                target = None
                if REPORT_CHANNEL_ID:
                    target = self.bot.get_channel(REPORT_CHANNEL_ID) or await self.bot.fetch_channel(REPORT_CHANNEL_ID)
                target = target or ch
                msg = f"[autolearn] <#{ch.id}> +{len(new_mems)} memori"
                if summary:
                    msg += f"\nsummary: {summary[:180]}"
                if help_needed and OWNER_USER_ID:
                    msg += f"\n<@{OWNER_USER_ID}> bantuan: {notify[:180]}"
                await target.send(msg)
                try:
                    self.bot.dispatch("neuro_autolearn_summary", {"channel_id": ch.id, "summary": summary, "count": len(new_mems)})
                except Exception:
                    pass
            except Exception:
                pass
        return added_total

async def setup(bot: commands.Bot):
    await bot.add_cog(NeuroAutoLearnModeratedV2(bot))
